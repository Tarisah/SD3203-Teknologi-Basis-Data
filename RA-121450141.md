---
jupyter:
  colab:
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.9.13
  nbformat: 4
  nbformat_minor: 0
---

::: {.cell .markdown id="l3iL9kfJdQ0b"}
## TUGAS TEKNOLOGI BASIS DATA

Nama : TARISAH

NIM : 121450141

Kelas : RA
:::

::: {.cell .markdown id="Gf17ePEHdQ0d"}
## Kumpulan Data Untuk di Proses
:::

::: {.cell .code id="9Vpj_uK0dQ0e" outputId="683a4e46-8f0b-4ed7-8a5b-9ddaa1b7eb0a"}
``` python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/ASUS/Downloads/cifar-10-python/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

::: {.output .stream .stdout}
    Loaded CIFAR-10 training set:
     - np.shape(images)     (50000, 32, 32, 3)
     - np.shape(labels)     (50000,)
:::
:::

::: {.cell .markdown id="0uWjOpX7dQ0i"}
Di awal, kita mengarahkan ke direktori penyimpanan data CIFAR-10 dan
mendefinisikan fungsi `unpickle()` untuk membaca file pickle.
Setelahnya, dua list kosong diciptakan: `images` untuk menyimpan gambar
dan `labels` untuk label setiap gambar.

Langkah selanjutnya adalah melakukan iterasi melalui setiap batch file
di direktori data. Masing-masing file di-unpickle untuk mendapatkan
informasi gambar dan labelnya. Gambar kemudian direkonstruksi dari data
piksel yang telah di-flatten. Karena setiap gambar memiliki tiga saluran
warna, data piksel dibagi menjadi tiga bagian dan kemudian digabungkan
kembali untuk membentuk gambar utuh.

Terakhir, ukuran `images` dan `labels` dicetak untuk memastikan bahwa
dataset telah dimuat dengan benar. Terdapat 5000 data
:::

::: {.cell .code id="aWkdfDOxdQ0i"}
``` python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
:::

::: {.cell .markdown id="-Rw7C2GZdQ0j"}
Setiap objek ini merepresentasikan alamat direktori: `disk_dir` menuju
direktori \"data/disk/\", `lmdb_dir` menuju \"data/lmdb/\", dan
`hdf5_dir` menuju \"data/hdf5/\". Dengan objek-objek ini, Anda dapat
dengan mudah melakukan operasi-operasi terkait file dan direktori
seperti manipulasi file, pembuatan direktori baru, atau pemeriksaan
keberadaan file.
:::

::: {.cell .code id="emBw9ZcrdQ0j"}
``` python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
:::

::: {.cell .markdown id="Oeo76hQDdQ0j"}
Kode di atas menggunakan metode `mkdir()` pada objek `Path` untuk
membuat direktori yang ditunjukkan oleh `disk_dir`, `lmdb_dir`, dan
`hdf5_dir`. Argumen `parents=True` digunakan untuk membuat direktori
induk jika tidak ada, sedangkan `exist_ok=True` memungkinkan pembuatan
direktori tersebut meskipun direktori tersebut sudah ada sebelumnya
tanpa memunculkan pesan error. Dengan demikian, kode ini secara efisien
membuat tiga direktori yang diperlukan untuk penyimpanan data dalam
proyek Anda.
:::

::: {.cell .code id="TzO3ldiZdQ0k"}
``` python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
:::

::: {.cell .markdown id="TZiH0vyhdQ0k"}
Kode tersebut adalah sebuah fungsi Python yang disusun untuk menyimpan
gambar dan labelnya ke dalam direktori yang telah dibuat sebelumnya
menggunakan objek `Path` yang Anda definisikan sebelumnya. Fungsi
`store_single_disk` menerima tiga argumen: gambar sebagai array dengan
dimensi (32, 32, 3), ID unik gambar sebagai integer, dan label gambar.
Pertama, gambar disimpan sebagai file .png di dalam direktori `disk_dir`
dengan nama file yang sesuai dengan ID gambar. Selanjutnya, label
disimpan ke dalam file .csv yang juga diletakkan di dalam direktori yang
sama dengan nama file yang mengandung ID gambar tersebut. Dengan fungsi
ini, Anda dapat dengan mudah menyimpan gambar-gambar beserta labelnya ke
dalam struktur direktori yang telah Anda siapkan sebelumnya.
:::

::: {.cell .code id="qetHTBJFdQ0k"}
``` python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
:::

::: {.cell .markdown id="ifV6ZfWTdQ0k"}
Kelas `CIFAR_Image` adalah sebuah kelas dalam Python yang digunakan
untuk merepresentasikan gambar dari dataset CIFAR. Dalam metode
`__init__`, kelas ini menginisialisasi objek dengan atribut-atribut
seperti jumlah channel (misalnya RGB memiliki tiga channel), dimensi
gambar, dan isi gambar yang dikonversi menjadi bytes. Selain itu, kelas
ini juga menyimpan label dari gambar tersebut. Metode `get_image`
digunakan untuk mengembalikan gambar dalam bentuk array numpy sesuai
dengan dimensi dan channel yang telah disimpan sebelumnya. Dengan kelas
ini, Anda dapat dengan mudah mengelola dan memproses gambar-gambar dari
dataset CIFAR dalam format yang sesuai untuk analisis lebih lanjut.
:::

::: {.cell .code id="ihnSdm6kdQ0l"}
``` python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```
:::

::: {.cell .markdown id="bpYcv7H4dQ0l"}
Kode di atas adalah sebuah fungsi Python yang digunakan untuk menyimpan
gambar ke dalam basis data LMDB (Lightning Memory-Mapped Database).
Fungsi `store_single_lmdb` menerima tiga argumen: gambar sebagai array
dengan dimensi (32, 32, 3), ID unik gambar sebagai integer, dan label
gambar. Pada bagian awal, variabel `map_size` dihitung berdasarkan
ukuran gambar untuk menentukan ukuran memori yang akan dialokasikan
untuk basis data LMDB.

Selanjutnya, sebuah lingkungan LMDB baru dibuat menggunakan `lmdb.open`
dengan parameter `map_size` yang telah dihitung sebelumnya. Kemudian,
transaksi tulis baru dimulai menggunakan `env.begin(write=True)`. Semua
pasangan kunci-nilai dalam LMDB harus berupa string, sehingga gambar dan
labelnya diwakili sebagai objek `CIFAR_Image` dan di-serialize
menggunakan modul `pickle`.

Setelah nilai kunci dan nilainya ditentukan, fungsi memasukkan data ke
dalam LMDB menggunakan `txn.put`. Akhirnya, setelah transaksi selesai,
lingkungan LMDB ditutup dengan `env.close()`. Dengan fungsi ini, Anda
dapat dengan mudah menyimpan gambar-gambar dari dataset CIFAR ke dalam
basis data LMDB untuk digunakan dalam analisis lebih lanjut.
:::

::: {.cell .code id="ByQmTg3ldQ0l"}
``` python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
:::

::: {.cell .markdown id="ce3az7vXdQ0l"}
Pertama, sebuah file HDF5 baru dibuat menggunakan `h5py.File` dengan
nama file yang sesuai dengan ID gambar. Selanjutnya, dataset untuk
gambar dan dataset untuk metadata (label) dibuat di dalam file HDF5
tersebut menggunakan `create_dataset`. Dataset untuk gambar diberi nama
\"image\" dengan tipe data `h5py.h5t.STD_U8BE` yang merepresentasikan
unsigned 8-bit integer big endian. Sedangkan dataset untuk metadata
diberi nama \"meta\" dengan tipe data yang sama seperti gambar. Data
dari gambar dan metadata dimasukkan ke dalam dataset masing-masing.

Setelah dataset dibuat dan diisi dengan data, file HDF5 ditutup dengan
`file.close()`. Dengan menggunakan fungsi ini, Anda dapat dengan mudah
menyimpan gambar-gambar beserta metadata-nya ke dalam file HDF5 untuk
digunakan dalam proses analisis data lebih lanjut.
:::

::: {.cell .code id="aiYoaW7VdQ0l"}
``` python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
:::

::: {.cell .markdown id="NJ-Y2X6vdQ0l"}
Baris kode di atas membuat sebuah kamus yang disebut
`_store_single_funcs` yang berisi tiga fungsi: `store_single_disk`,
`store_single_lmdb`, dan `store_single_hdf5`, masing-masing terkait
dengan metode penyimpanan data yang berbeda (`disk`, `lmdb`, dan
`hdf5`). Ini memungkinkan penggunaan kamus ini untuk memilih metode
penyimpanan yang sesuai dengan kebutuhan aplikasi, dengan cukup
memanggil fungsi yang sesuai dengan kunci yang diinginkan (seperti
`'disk'` untuk penyimpanan di disk, `'lmdb'` untuk penyimpanan di LMDB,
dan `'hdf5'` untuk penyimpanan di HDF5). Dengan cara ini, fleksibilitas
dalam memilih cara penyimpanan data dapat diterapkan dengan mudah dalam
program Anda.
:::

::: {.cell .code id="SYtb3MiedQ0l" outputId="8d05d750-3803-4a24-8f3e-e4d3b029ea3f"}
``` python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.14079929999979868
    Method: lmdb, Time usage: 0.005631300000004558
    Method: hdf5, Time usage: 0.06091969999988578
:::
:::

::: {.cell .markdown id="uJUzlRBOdQ0m"}
Dari hasil tersebut, dapat disimpulkan bahwa metode lmdb adalah yang
paling cepat dalam hal waktu penyimpanan data, diikuti oleh metode hdf5,
dan metode disk merupakan yang memakan waktu paling lama di antara
ketiganya. Informasi ini berguna untuk mengevaluasi performa relatif
dari berbagai metode penyimpanan data dan memilih yang paling sesuai
berdasarkan kebutuhan aplikasi.
:::

::: {.cell .code id="tYf2psQPdQ0m"}
``` python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
:::

::: {.cell .markdown id="k12q0XyydQ0m"}
Fungsi `store_many_disk` digunakan untuk menyimpan sebuah array gambar
beserta labelnya ke dalam disk dengan menyimpan setiap gambar dalam
format .png dan labelnya dalam sebuah file .csv terpisah.

Fungsi `store_many_lmdb` digunakan untuk menyimpan sebuah array gambar
beserta labelnya ke dalam basis data LMDB dengan menyimpan setiap gambar
dan labelnya dalam sebuah transaksi tunggal di dalam basis data
tersebut.

Fungsi `store_many_hdf5` digunakan untuk menyimpan sebuah array gambar
beserta labelnya ke dalam sebuah file HDF5 dengan menyimpan seluruh
array gambar dalam satu dataset bernama \"images\" dan seluruh array
label dalam satu dataset bernama \"meta\".

Ketiga fungsi tersebut menerima dua argumen: array gambar dengan dimensi
(N, 32, 32, 3) dan array label dengan dimensi (N, 1), di mana N adalah
jumlah gambar yang akan disimpan.
:::

::: {.cell .code id="7CWeS0TZdQ0n" outputId="18eee4ab-47e4-4c11-c94f-e432f7ccd358"}
``` python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

::: {.output .stream .stdout}
    (100000, 32, 32, 3)
    (100000,)
:::
:::

::: {.cell .markdown id="grRW2o2SdQ0n"}
Hasil output tersebut menunjukkan bahwa setelah menggandakan jumlah
gambar (images) dan label (labels) dari sebelumnya, sekarang terdapat
100.000 gambar dalam bentuk array dengan dimensi (100000, 32, 32, 3) dan
100.000 label dalam bentuk array dengan dimensi (100000,). Hal ini
dibuktikan oleh hasil print dari `np.shape(images)` yang menunjukkan
dimensi (100000, 32, 32, 3) dan `np.shape(labels)` yang menunjukkan
dimensi (100000,). Dengan kata lain, jumlah gambar dan label telah
berhasil ditingkatkan menjadi 100.000 sesuai dengan yang diinginkan.
:::

::: {.cell .code id="ALDqesjJdQ0n" outputId="951c9d5b-a896-440c-bf7d-8cb23787df20"}
``` python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.043001499999945736
    Method: lmdb, Time usage: 0.013635200000180703
    Method: hdf5, Time usage: 0.054849900000135676
    Method: disk, Time usage: 0.16676769999980934
    Method: lmdb, Time usage: 0.005678900000020803
    Method: hdf5, Time usage: 0.0023858000001837354
    Method: disk, Time usage: 1.6323519000000033
    Method: lmdb, Time usage: 0.03800269999987904
    Method: hdf5, Time usage: 0.005430300000170973
    Method: disk, Time usage: 12.146795200000042
    Method: lmdb, Time usage: 0.29728830000021844
    Method: hdf5, Time usage: 0.025982599999679223
    Method: disk, Time usage: 142.75358489999962
    Method: lmdb, Time usage: 4.296912700000121
    Method: hdf5, Time usage: 0.46554439999999886
:::
:::

::: {.cell .markdown id="UEy2hIv8dQ0n"}
Hasil output tersebut menunjukkan waktu yang dibutuhkan (dalam detik)
oleh setiap metode (`disk`, `lmdb`, `hdf5`) untuk menyimpan sejumlah
gambar dan label yang berbeda-beda berdasarkan nilai cutoff yang
ditentukan sebelumnya (10, 100, 1000, 10000, 100000).

Pertama, pada saat nilai cutoff adalah 10, waktu yang dibutuhkan untuk
metode `disk` adalah sekitar 0.043 detik, untuk metode `lmdb` adalah
sekitar 0.013 detik, dan untuk metode `hdf5` adalah sekitar 0.054 detik.

Kedua, ketika nilai cutoff adalah 100, waktu yang dibutuhkan untuk
metode `disk` naik menjadi sekitar 0.167 detik, sementara metode `lmdb`
menjadi sekitar 0.005 detik, dan metode `hdf5` menjadi sekitar 0.002
detik.

Ketiga, ketika nilai cutoff terus bertambah hingga mencapai 100000,
waktu yang dibutuhkan juga meningkat secara signifikan. Metode `disk`
membutuhkan waktu sekitar 12.147 detik, metode `lmdb` membutuhkan waktu
sekitar 0.297 detik, dan metode `hdf5` membutuhkan waktu sekitar 0.026
detik.

Dari hasil ini, dapat dilihat bahwa performa relatif dari masing-masing
metode berbeda tergantung pada jumlah data yang disimpan. Metode `lmdb`
cenderung memiliki waktu eksekusi yang lebih singkat dibandingkan dengan
`disk` dan `hdf5`, terutama saat jumlah data yang disimpan semakin
besar. Sedangkan `disk` cenderung membutuhkan waktu lebih lama karena
operasi I/O pada disk, sedangkan `hdf5` memiliki waktu eksekusi yang
stabil tergantung pada jumlah data yang disimpan.
:::

::: {.cell .code id="9mTfFCSAdQ0n" outputId="a6867cd0-f37c-4aa3-8861-82c022627fbf"}
``` python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

::: {.output .stream .stderr}
    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
:::

::: {.output .display_data}
![](vertopal_133340be8d5a48b994f506218faf8079/7162a3c384d7ee9787d100df609eed34319f5bf5.png)
:::

::: {.output .stream .stderr}
    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
:::

::: {.output .display_data}
![](vertopal_133340be8d5a48b994f506218faf8079/c39ac9c3a10747bb7a215a637405fcb7a1a7e494.png)
:::
:::

::: {.cell .code id="EYpvhN1hdQ0n"}
``` python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```
:::

::: {.cell .markdown id="QqPQlWOrdQ0o"}
Fungsi `read_single_disk` ini digunakan untuk membaca sebuah gambar dan
labelnya yang telah disimpan dalam disk. Gambar dibaca menggunakan
`Image.open` dari modul PIL dan kemudian diubah menjadi array numpy.
Labelnya dibaca dari file CSV yang sesuai dengan ID gambar.

Setelah membaca gambar dan labelnya, fungsi ini mengembalikan gambar
dalam bentuk array dengan dimensi (32, 32, 3) dan labelnya dalam bentuk
integer. Dengan demikian, fungsi ini memungkinkan untuk membaca kembali
data gambar dan label yang telah disimpan dalam format yang telah
ditentukan sebelumnya di dalam disk.
:::

::: {.cell .code id="ITE14aJidQ0o"}
``` python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```
:::

::: {.cell .markdown id="eHwS84vYdQ0o"}
Kode `read_single_lmdb` berfungsi untuk membaca sebuah gambar dan label
yang tersimpan dalam basis data LMDB. Fungsi ini menerima satu argumen
yaitu `image_id`, yang merupakan ID unik untuk gambar yang akan dibaca.

Pertama, lingkungan LMDB dibuka dengan mode hanya baca (readonly=True)
menggunakan `lmdb.open`. Selanjutnya, transaksi baca baru dimulai dengan
`env.begin()`. Key yang digunakan untuk mengambil data harus diencode
dengan metode yang sama saat menyimpan data.

Kemudian, data gambar diambil dari basis data LMDB dengan menggunakan
`txn.get`. Data tersebut di-decode menggunakan `pickle.loads` karena
data gambar disimpan sebagai objek CIFAR_Image saat disimpan.

Setelah data diambil, gambar direkonstruksi menggunakan metode
`get_image()` dari objek CIFAR_Image, dan labelnya diambil langsung dari
atribut label pada objek tersebut.

Terakhir, lingkungan LMDB ditutup dan gambar beserta labelnya
dikembalikan sebagai output dari fungsi. Dengan fungsi ini, Anda dapat
dengan mudah membaca gambar dan label dari basis data LMDB berdasarkan
ID unik gambar yang diberikan.
:::

::: {.cell .code id="R6WLtPVkdQ0o"}
``` python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```
:::

::: {.cell .markdown id="7-A2TSfxdQ0o"}
Fungsi `read_single_hdf5` digunakan untuk membaca sebuah gambar dan
label yang tersimpan dalam file HDF5. Fungsi ini menerima satu argumen
yaitu `image_id`, yang merupakan ID unik untuk gambar yang akan dibaca.

Pertama, file HDF5 dibuka dengan mode baca dan tulis (r+ mode)
menggunakan `h5py.File`. Kemudian, gambar dibaca dari dataset \"image\"
dalam file HDF5 dan diubah menjadi array numpy dengan tipe data `uint8`
(unsigned integer 8-bit). Selanjutnya, label dibaca dari dataset
\"meta\" dan juga diubah menjadi integer dengan tipe data `uint8`.

Setelah membaca data gambar dan label, file HDF5 ditutup dan gambar
beserta labelnya dikembalikan sebagai output dari fungsi.

Dengan fungsi ini, Anda dapat dengan mudah membaca gambar dan label dari
file HDF5 berdasarkan ID unik gambar yang diberikan.
:::

::: {.cell .code id="zr3vAva1dQ0o"}
``` python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```
:::

::: {.cell .markdown id="jUgPLMQidQ0o"}
Kode `_read_single_funcs` membuat sebuah kamus yang berisi tiga fungsi:
`read_single_disk`, `read_single_lmdb`, dan `read_single_hdf5`,
masing-masing terkait dengan metode membaca data dari lokasi penyimpanan
yang berbeda (`disk`, `lmdb`, dan `hdf5`). Hal ini memungkinkan
penggunaan kamus ini untuk memilih metode membaca yang sesuai dengan
kebutuhan aplikasi, dengan cukup memanggil fungsi yang sesuai dengan
kunci yang diinginkan (seperti `'disk'` untuk membaca dari disk,
`'lmdb'` untuk membaca dari LMDB, dan `'hdf5'` untuk membaca dari HDF5).
Dengan cara ini, fleksibilitas dalam memilih cara membaca data dapat
diterapkan dengan mudah dalam program Anda.
:::

::: {.cell .code id="sOEB42NMdQ0o" outputId="4cdd242a-2613-459a-e7a7-3ffd37cff314"}
``` python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.03221690000009403
    Method: lmdb, Time usage: 0.029903999999987718
    Method: hdf5, Time usage: 0.020119400000112364
:::
:::

::: {.cell .markdown id="apMEbBAbdQ0o"}
Hasil output tersebut menunjukkan waktu yang dibutuhkan (dalam detik)
oleh masing-masing metode (`disk`, `lmdb`, `hdf5`) untuk membaca sebuah
gambar dan label dari lokasi penyimpanan yang berbeda.

Dari hasil tersebut, dapat disimpulkan bahwa metode `hdf5` adalah yang
paling cepat dalam hal waktu membaca data, diikuti oleh metode `lmdb`,
dan metode `disk` merupakan yang memakan waktu paling lama di antara
ketiganya. Informasi ini berguna untuk mengevaluasi performa relatif
dari berbagai metode membaca data dan memilih yang paling sesuai
berdasarkan kebutuhan aplikasi.
:::

::: {.cell .code id="AX0yYUNtdQ0o"}
``` python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
:::

::: {.cell .markdown id="pedZpjYsdQ0p"}
Kode di atas mendefinisikan tiga fungsi, `read_many_disk`,
`read_many_lmdb`, dan `read_many_hdf5`, untuk membaca sejumlah gambar
dan label dari berbagai lokasi penyimpanan (disk, LMDB, HDF5).

Fungsi `read_many_disk` membaca gambar dan label dari disk dengan
membuka file .png untuk setiap gambar dan file .csv untuk labelnya.
Proses pembacaan dilakukan dengan loop dan menggunakan modul PIL untuk
membaca gambar.

Fungsi `read_many_lmdb` membaca gambar dan label dari basis data LMDB
dengan membuka transaksi baca menggunakan modul lmdb. Proses pembacaan
dilakukan dengan loop untuk mengambil data gambar dan label dari setiap
kunci yang sesuai dalam basis data.

Fungsi `read_many_hdf5` membaca gambar dan label dari file HDF5 dengan
membuka file HDF5 dan membaca dataset \"images\" dan \"meta\" dari file
tersebut.

Kamus `_read_many_funcs` digunakan untuk mengelompokkan ketiga fungsi
pembacaan tersebut berdasarkan lokasi penyimpanan yang berbeda (disk,
LMDB, HDF5).

Kode ini memungkinkan untuk membaca sejumlah gambar dan label dari
berbagai lokasi penyimpanan dengan mudah dan fleksibel, tergantung pada
kebutuhan aplikasi.
:::

::: {.cell .code id="fXKxR4W0dQ0y" outputId="4452c5d6-a5b9-4058-d6fd-12cda2512ef1"}
``` python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

::: {.output .error ename="IndexError" evalue="list index out of range"}
    ---------------------------------------------------------------------------
    IndexError                                Traceback (most recent call last)
    Cell In [47], line 7
          5 for cutoff in cutoffs:
          6     for method in ("disk", "lmdb", "hdf5"):
    ----> 7         t = timeit(
          8             "_read_many_funcs[method](num_images)",
          9             setup="num_images=cutoff",
         10             number=1,
         11             globals=globals(),
         12         )
         13         read_many_timings[method].append(t)
         15         # Print out the method, cutoff, and elapsed time

    File c:\Users\ASUS\AppData\Local\Programs\Python\Python39\lib\timeit.py:233, in timeit(stmt, setup, timer, number, globals)
        230 def timeit(stmt="pass", setup="pass", timer=default_timer,
        231            number=default_number, globals=None):
        232     """Convenience function to create Timer object and call timeit method."""
    --> 233     return Timer(stmt, setup, timer, globals).timeit(number)

    File c:\Users\ASUS\AppData\Local\Programs\Python\Python39\lib\timeit.py:177, in Timer.timeit(self, number)
        175 gc.disable()
        176 try:
    --> 177     timing = self.inner(it, self.timer)
        178 finally:
        179     if gcold:

    File <timeit-src>:6, in inner(_it, _timer)

    Cell In [42], line 23, in read_many_disk(num_images)
         19     reader = csv.reader(
         20         csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
         21     )
         22     for row in reader:
    ---> 23         labels.append(int(row[0]))
         24 return images, labels

    IndexError: list index out of range
:::
:::

::: {.cell .markdown id="9t-jFVRPdQ0z"}
Kode di atas mengukur waktu yang dibutuhkan untuk membaca sejumlah
gambar dari berbagai metode penyimpanan (disk, LMDB, HDF5) dengan
menggunakan `timeit`. Hasil pengukuran waktu disimpan dalam kamus
`read_many_timings`.

Pada setiap iterasi, kode melakukan pengukuran waktu untuk membaca
sejumlah gambar (`num_images`) berdasarkan metode penyimpanan yang
ditentukan dalam variabel `method`. Pengukuran waktu dilakukan sekali
saja (number=1) untuk setiap metode.

Hasil pengukuran waktu kemudian disimpan dalam kamus `read_many_timings`
untuk masing-masing metode penyimpanan.

Selain itu, kode juga mencetak informasi tentang metode penyimpanan,
jumlah gambar yang dibaca, dan waktu yang dibutuhkan untuk pembacaan
tersebut.

Kode ini memberikan informasi yang berguna untuk mengevaluasi performa
relatif dari berbagai metode pembacaan data tergantung pada jumlah
gambar yang dibaca (`cutoff`) dari setiap metode penyimpanan.
:::
